
**使用Kubeadm搭建Kubernetes1.16.2集群，宿主机使用9.1里搭建的master、node1、node2、node3四台虚拟机，即一主三从的K8S集群结构**

# 目录

* [1. 安装准备](#1-安装准备)
  * [master虚拟机安装准备](#master虚拟机安装准备)
  * [node1虚拟机安装准备](#node1虚拟机安装准备)
  * [node2虚拟机安装准备](#node2虚拟机安装准备)
  * [node3虚拟机安装准备](#node3虚拟机安装准备)
* [2. 安装kubeadm等工具](#2-安装kubeadm等工具)  
  * [master机上安装kubeadm等工具](#master机上安装kubeadm等工具)
  * [node1机上安装kubeadm等工具](#node1机上安装kubeadm等工具)
  * [node2机上安装kubeadm等工具](#node2机上安装kubeadm等工具)
  * [node3机上安装kubeadm等工具](#node3机上安装kubeadm等工具)
* [3. 安装Master节点](#3-安装Master节点)  
  * [3.1 安装Master节点在master虚拟机上](#安装Master节点在master虚拟机上)
* [4. 安装Node节点](#4-安装Node节点)
  * [4.1 在node1虚拟机上安装Node节点](#在node1虚拟机上安装Node节点)
  * [4.2 在node2虚拟机上安装Node节点](#在node2虚拟机上安装Node节点)
  * [4.3 在node3虚拟机上安装Node节点](#在node3虚拟机上安装Node节点)
---

# 1 安装准备

**在搭建K8S集群之前，我们需要对虚拟机进行一些操作。下面这些操作需要在master、node1、node2、node3四台虚拟机上执行，这里以master为例,但是我会把每一台机的配置步骤都写出来**

## master虚拟机安装准备

    1.安装必要软件：

        [root@master]# yum install -y net-tools.x86_64 wget
    
    2.配置hosts：

        [root@master]# vi /etc/hosts
        内容如下所示：

        192.168.33.11 master
        192.168.33.12 node1
        192.168.33.13 node2
        192.168.33.14 node3

    3.关闭防火墙：

      为了避免kubernetes的Master节点和各个工作节点的Node节点间的通信出现问题，我们可以关闭本地搭建的Centos虚拟机的防火墙。

      [root@master]# systemctl disable firewalld
      [root@master]# systemctl stop firewalld

    4.禁用SELinux，让容器可以顺利地读取主机文件系统：

      [root@master]# setenforce 0

      [root@master]# sed -i 's/^SELINUX=enforcing$/SELINUX=disabled/' /etc/selinux/config
     
    5.修改Docker配置：

        [root@master]# vi /etc/docker/daemon.json
        在{}内追加如下内容：

        "exec-opts": ["native.cgroupdriver=systemd"]

        内容如下：
        
        {
          “registry-mirrors”：[                             //配置镜像加速器
             "https://dockerhub.azk8s.cn",
             "https://reg-mirror.qiniu.com",
             "https://registry.docker-cn.com"
          ],
          "exec-opts": ["native.cgroupdriver=systemd"]     //新增加的内容  修改cgroupdriver是为了消除告警：[WARNING IsDockerSystemdCheck]: detected “cgroupfs” as the Docker 
                                                                          cgroup driver. The recommended driver is “systemd”. Please follow the guide 
                                                                          at https://kubernetes.io/docs/setup/cri/
        }

        重启docker：

        [root@master]# systemctl daemon-reload
        [root@master]# systemctl restart docker

      6. 内核参数修改, 将桥接的IPv4流量传递到iptables的链,
         本文的k8s网络使用flannel，该网络需要设置内核参数bridge-nf-call-iptables=1，修改这个参数需要系统有br_netfilter模块
         
         6.1 br_netfilter模块加载
             查看br_netfilter模块：

             [root@master01 ~]# lsmod |grep br_netfilter
             如果系统没有br_netfilter模块则执行下面的新增命令，如有则忽略。

             临时新增br_netfilter模块:

             [root@master01 ~]# modprobe br_netfilter
             该方式重启后会失效

             or
             
             永久新增br_netfilter模块：

             [root@master01 ~]# cat > /etc/rc.sysinit << EOF
             #!/bin/bash
             for file in /etc/sysconfig/modules/*.modules ; do
             [ -x $file ] && $file
             done
             EOF
             
             [root@master01 ~]# cat > /etc/sysconfig/modules/br_netfilter.modules << EOF
             modprobe br_netfilter
             EOF
                          
             [root@master01 ~]# chmod 755 /etc/sysconfig/modules/br_netfilter.modules

         6.2 内核参数修改
       
            //  内核参数临时修改
            
            [root@master]# sysctl net.bridge.bridge-nf-call-iptables = 1
            [root@master]# sysctl net.bridge.bridge-nf-call-ip6tables = 1
            
            or 
            
            //内核参数永久修改
        
             [root@master]#cat > /etc/sysctl.d/k8s.conf << EOF
                           >  net.bridge.bridge-nf-call-ip6tables = 1
                           >  net.bridge.bridge-nf-call-iptables = 1
                           >  EOF

             [root@master]# sysctl --system
         
             or 
         
             [root@master]# sysctl -p /etc/sysctl.d/k8s.conf

      7.关闭swap

          Swap是操作系统在内存吃紧的情况申请的虚拟内存，按照Kubernetes官网的说法，Swap会对Kubernetes的性能造成影响，不推荐使用Swap。

          [root@master]# echo "vm.swappiness = 0">> /etc/sysctl.conf 
          [root@master]# swapoff -a        //临时禁用
          
          or
          
          //若需要重启后也生效，在禁用swap后还需修改配置文件/etc/fstab，注释swap
          
          [root@master]# sed -i.bak '/swap/s/^/#/' /etc/fstab       //永久禁用

## node1虚拟机安装准备


## node2虚拟机安装准备

## node3虚拟机安装准备

---

# 2 安装kubeadm等工具

**准备工作完毕后，接着在master、node1、node2、node3四台虚拟机上安装kubeadm相关工具。下面这些操作需要在master、node1、node2、node3四台虚拟机上执行，这里以master为例**

## master机上安装kubeadm等工具

         1.配置国内的kubernetes源：

          [root@master]# vi /etc/yum.repos.d/kubernetes.repo

                         [kubernetes]
                         name=Kubernetes
                         baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/
                         enabled=1
                         gpgcheck=1
                         repo_gpgcheck=1
                         gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com
                         /kubernetes/yum/doc/rpm-package-key.gpg
                         
                         
                       [] 中括号中的是repository id，唯一，用来标识不同仓库
                       name 仓库名称，自定义
                       baseurl 仓库地址
                       enable 是否启用该仓库，默认为1表示启用
                       gpgcheck 是否验证从该仓库获得程序包的合法性，1为验证
                       repo_gpgcheck 是否验证元数据的合法性 元数据就是程序包列表，1为验证
                       gpgkey=URL 数字签名的公钥文件所在位置，如果gpgcheck值为1，此处就需要指定gpgkey文件的位置，如果gpgcheck值为0就不需要此项了  
         
         2. 更新缓存
            [root@master]# yum clean all
            [root@master]# yum -y makecache
          
         3.安装kubelet、kubeadm和kubectl工具：

           //版本查看
           [root@master]#   yum list kubelet --showduplicates | sort -r 

           //若不指定版本直接运行‘yum install -y kubelet kubeadm kubectl’则默认安装最新版
           [root@master]# yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

         4.启动kubelet并设置开机自启：     
         
           [root@master]# systemctl enable kubelet
           [root@master]# systemctl start kubelet

         5. Kubernetes几乎所有的安装组件和Docker镜像都放在goolge自己的网站上,直接访问可能会有网络问题，这里的解决办法是从阿里云镜像仓库下载镜像，拉取到本地以后改回默认的镜像tag
           
           5.1 建立镜像下载的脚本
           
              [root@master]# more image.sh 
                             #!/bin/bash
                             url=registry.cn-hangzhou.aliyuncs.com/google_containers   or url=registry.aliyuncs.com/google_containers
                             version=v1.19.0
                             images=(`kubeadm config images list --kubernetes-version=$version|awk -F '/' '{print $2}'`)
                             for imagename in ${images[@]} ; do
                               docker pull $url/$imagename
                               docker tag $url/$imagename k8s.gcr.io/$imagename
                               docker rmi -f $url/$imagename
                             done

              url为阿里云镜像仓库地址，version为安装的kubernetes版本
 
           5.2  运行脚本image.sh，下载指定版本的镜像，运行脚本前先赋权
         
              [root@master ~]# chmod u+x image.sh   //赋权
              [root@master ~]# ./image.sh           //运行脚本image.sh  
              [root@master ~]# docker images        //查看下载后的镜像


## node1机上安装kubeadm等工具

## node2机上安装kubeadm等工具

## node3机上安装kubeadm等工具

---

# 3 安装Master节点

## 安装Master节点在master虚拟机上

**安装好kubeadm等相关工具后，接着在master虚拟机上执行以下操作：使用下面这条命令启动 master节点**

      // 初始化
      [root@master]# kubeadm init --kubernetes-version=v1.19.0 
                                  --pod-network-cidr=10.244.0.0/16 
                                  --service-cidr=10.1.0.0/16 
                                  --apiserver-advertise-address=192.168.33.11 
                                  --image-repository registry.aliyuncs.com/google_containers
      
      配置含义如下：

       kubernetes-version: 用于指定k8s版本，这里指定为最新的1.16.2版本；
       apiserver-advertise-address：用于指定kube-apiserver监听的ip地址，就是master本机IP地址。
       pod-network-cidr：因为后面我们选择flannel作为Pod的网络插件，所以这里需要指定Pod的网络范围为10.244.0.0/16
       service-cidr：用于指定SVC的网络范围；
       image-repository: 其中默认的镜像仓库k8s.gcr.io没有科学上网的话无法访问，我们可以将它修改为国内的阿里镜像仓
                         库registry.aliyuncs.com/google_containers

       启动成功后，你会看到类似如下提示:
       
            Your Kubernetes control-plane has initialized successfully!

            To start using your cluster, you need to run the following as a regular user:

              mkdir -p $HOME/.kube
              sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
              sudo chown $(id -u):$(id -g) $HOME/.kube/config

            You should now deploy a pod network to the cluster.
            Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
              https://kubernetes.io/docs/concepts/cluster-administration/addons/

            Then you can join any number of worker nodes by running the following on each as root:

            //而下面这段则是用于工作节点Node加入Master集群用的，而它的令牌号数是每次执行 kubernetes init 命令都不同的
            
            kubeadm join 192.168.33.11:6443 --token 0na0jo.e9svsj5tmeciad88 --discovery-token-ca-cert-hash sha256:5fbcc1a1167d0
                                      db98d0fc6c037a06378899978d4c811c61a271f2bf116810e93
            
            
  <a href="https://ibb.co/wMsPnZ7"><img src="https://i.ibb.co/6gBTKc8/kubeadm-token-number.jpg" alt="kubeadm-token-number" border="0"></a>
            
            意思是，初始化成功，要开始使用K8S集群的话，需要执行以下命令:
            
            [root@master]# mkdir -p $HOME/.kube
            [root@master]# cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
            [root@master]# chown $(id -u):$(id -g) $HOME/.kube/config
       
# 4 安装Node节点

**接着在node1、node2、node3三台虚拟机上安装Node节点，在node1、node2和node3节点上执行下面这条命令，加入Master**

## 在node1虚拟机上安装Node节点

   [root@node1]# kubeadm join 192.168.33.11:6443 --token 0na0jo.e9svsj5tmeciad88 --discovery-token-ca-cert-hash sha256:5fbcc1a1167d0
                                      db98d0fc6c037a06378899978d4c811c61a271f2bf116810e93





## 在node2虚拟机上安装Node节点

   [root@node1]# kubeadm join 192.168.33.11:6443 --token 0na0jo.e9svsj5tmeciad88 --discovery-token-ca-cert-hash sha256:5fbcc1a1167d0
                                      db98d0fc6c037a06378899978d4c811c61a271f2bf116810e93


## 在node3虚拟机上安装Node节点

   [root@node1]# kubeadm join 192.168.33.11:6443 --token 0na0jo.e9svsj5tmeciad88 --discovery-token-ca-cert-hash sha256:5fbcc1a1167d0
                                      db98d0fc6c037a06378899978d4c811c61a271f2bf116810e93
